{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "# projects = ['abinit', 'libmesh', 'lammps', 'mdanalysis']\n",
    "projects = ['libmesh']\n",
    "for sp in projects:\n",
    "    s = \"/Users/saurabh/workspace/fss/project/data/data-collection/labeled_commits/{}/\".format(sp)\n",
    "    path = s\n",
    "    files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    all_files.extend(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = \"/Users/saurabh/workspace/fss/project/data/data-collection/labeled_commits/auto/abinit_concat.csv\"\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_df = pd.read_csv(fname, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "raw_df = concatenated_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buggy\n",
      "0.0    7913\n",
      "1.0     835\n",
      "Name: hash, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "buggies = raw_df.groupby(\"buggy\")[\"hash\"].count()\n",
    "print(buggies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_n = 1000\n",
    "# drop_indices = np.random.choice(raw_df.index, remove_n, replace=False)\n",
    "# new_df = raw_df.drop(drop_indices)\n",
    "# b = new_df.groupby(\"buggy\")[\"hash\"].count()\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash        object\n",
      "time        object\n",
      "message     object\n",
      "buggy      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(raw_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8748, 4)\n",
      "(8745, 4)\n"
     ]
    }
   ],
   "source": [
    "# inft = []\n",
    "# for el in y:\n",
    "#     if not np.isfinite(el):\n",
    "#         inft.append(el)\n",
    "# print(el)\n",
    "print(raw_df.shape)\n",
    "raw_df = raw_df.dropna()\n",
    "print(raw_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw = raw_df['buggy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                    [a, number, of, minor, change, .]\n",
      "1                              [cv, ignores, for, sgi]\n",
      "2    [this, commit, wa, manufactured, by, cvs2svn, ...\n",
      "3    [can, now, write, a, file, in, parallel, --, t...\n",
      "4              [updated, compatible, to, new, doxygen]\n",
      "Name: tknz_msg, dtype: object\n"
     ]
    }
   ],
   "source": [
    "raw_df['tknz_msg'] = raw_df['message'].apply(wordpunct_tokenize).apply(lambda tkns: [lemmatizer.lemmatize(w.lower()) for w in tkns])\n",
    "print(raw_df['tknz_msg'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                              [number, minor, change]\n",
      "1                                       [ignores, sgi]\n",
      "2    [commit, manufactured, cvs2svn, create, tag, l...\n",
      "3    [write, file, parallel, format, identical, exi...\n",
      "4                  [updated, compatible, new, doxygen]\n",
      "Name: msg, dtype: object\n"
     ]
    }
   ],
   "source": [
    "raw_df['msg'] = raw_df['tknz_msg']\\\n",
    "    .apply(lambda tkns: \\\n",
    "           list(filter(\\\n",
    "                       lambda word: word not in stopset \\\n",
    "                       and word not in string.punctuation\\\n",
    "                       and len(word) > 2\\\n",
    "                       , tkns)))\n",
    "print(raw_df['msg'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = raw_df['msg'].apply(pd.Series).stack().drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(words))\n",
    "# print(words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['msg_str'] = raw_df['msg'].apply(lambda tkns: ' '.join(tkns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_features = min(1000, len(words))\n",
    "no_features = 100\n",
    "\n",
    "# tfidf_vectorizer = TfidfVectorizer(max_features=no_features)\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.95, min_df=2, max_features=no_features)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(raw_df['msg_str'])\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_features=no_features)\n",
    "X_tf = tf_vectorizer.fit_transform(raw_df['msg_str'])\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf vectorized:  (8745, 100)\n",
      "tf vectorized:  (8745, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"tf-idf vectorized: \", X_tfidf.shape)\n",
    "print(\"tf vectorized: \", X_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 2\n",
    "num_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=no_topics, max_iter=num_iter, learning_method='online', learning_offset=50.,random_state=9, evaluate_every=100).fit(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8745, 2)\n"
     ]
    }
   ],
   "source": [
    "lda_x = lda.transform(X_tf)\n",
    "print(lda_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = [\"bug\", \"fix\", \"wrong\", \"error\", \"fail\", \"problem\", \"patch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "#         print(\"Topic %d:\" % (topic_idx))\n",
    "        top_features = [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "#         print(\" \".join(top_features))\n",
    "        if any(bug_word in top_features for bug_word in key_words):\n",
    "            print(\"Topic %d:\" % (topic_idx))\n",
    "            print(\" \".join(top_features))\n",
    "            topic_indices.append(topic_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "added used change elem fix meshbase fixed jwpeterson error need\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "# display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "display_topics(lda, tf_feature_names, no_top_words)\n",
    "print(topic_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_top_map = {}\n",
    "def get_topic_top_words(model, feature_names):\n",
    "    if str(model) in model_top_map:\n",
    "        return model_top_map[str(model)]\n",
    "    topic_top_words = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "            top_words = [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "            topic_top_words.append(top_words)\n",
    "    model_top_map[str(model)] = topic_top_words\n",
    "    return topic_top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_topics(words, no_top_words, model, feature_names):\n",
    "    topic_ranks = []\n",
    "    topic_top_words = get_topic_top_words(model, feature_names)\n",
    "    for top_words in topic_top_words:\n",
    "        topic_freq = 0\n",
    "        for w in words:\n",
    "            if w in top_words:\n",
    "                topic_freq += 1\n",
    "        topic_ranks.append(topic_freq)\n",
    "    buggy_topic = 0\n",
    "    max_val = max(topic_ranks)\n",
    "    idx = topic_ranks.index(max_val)\n",
    "    if idx in topic_indices:\n",
    "        buggy_topic = 1\n",
    "    return max_val, idx, buggy_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['topic_freq'], raw_df['topic_id'], raw_df['buggy_topic'] = zip(*raw_df['msg'].apply(lambda tkns: get_top_topics(tkns, 20, lda, tf_feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(raw_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  (1, 0.0) value:  1979\n",
      "index:  (1, 1.0) value:  633\n"
     ]
    }
   ],
   "source": [
    "tops_labels = raw_df.groupby(['topic_id','buggy']).size()\n",
    "for i, v in tops_labels.items():\n",
    "    if i[0] in topic_indices:\n",
    "        print('index: ', i, 'value: ', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "final_df = raw_df[raw_df['buggy'] == 1]\n",
    "if len(topic_indices) > 0:\n",
    "    for idx in topic_indices:\n",
    "        final_df = final_df.append(raw_df[raw_df['topic_id'] == idx])\n",
    "    test_df = raw_df[(raw_df['hash'].apply(lambda x: x not in final_df['hash'].values))]\n",
    "else:\n",
    "    final_df = raw_df\n",
    "# final_df = raw_df\n",
    "use_all_as_test = False\n",
    "if not test_df.empty and test_df.size > 0:\n",
    "    use_all_as_test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8745, 10)\n",
      "(3447, 10)\n",
      "(5897, 10)\n"
     ]
    }
   ],
   "source": [
    "print(raw_df.shape)\n",
    "print(final_df.shape)\n",
    "if use_all_as_test:\n",
    "    print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_X_tf = tf_vectorizer.transform(final_df['msg_str'])\n",
    "# X = lda.transform(final_X_tf)\n",
    "X = tfidf_vectorizer.transform(final_df['msg_str'])\n",
    "y = final_df['buggy']\n",
    "if use_all_as_test:\n",
    "#     test_X_tf = tf_vectorizer.transform(test_df['msg_str'])\n",
    "#     test_X = lda.transform(test_X_tf)\n",
    "    test_X = tf_vectorizer.transform(test_df['msg_str'])\n",
    "    test_y = test_df['buggy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3447, 100)\n",
      "(3447,)\n",
      "(3447, 100)\n",
      "(5897, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# X = hstack((X,np.array(final_df['topic_id'])[:,None]))\n",
    "# X = hstack((X,np.array(final_df['topic_freq'])[:,None]))\n",
    "# X = hstack((X,np.array(final_df['buggy_topic'])[:,None]))\n",
    "print(X.shape)\n",
    "if use_all_as_test:\n",
    "#     test_X = hstack((test_X,np.array(test_df['topic_id'])[:,None]))\n",
    "#     test_X = hstack((test_X,np.array(test_df['topic_freq'])[:,None]))\n",
    "#     test_X = hstack((test_X,np.array(test_df['buggy_topic'])[:,None]))\n",
    "    print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=9, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# positive in train set: 1101 \n",
      "# negative in train set: 1484\n",
      "# positive in test set: 367 \n",
      "# negative in test set: 495\n"
     ]
    }
   ],
   "source": [
    "print(\"# positive in train set: {}\".format(len(y_train[y_train == 1])),\n",
    "      \"\\n# negative in train set: {}\".format(len(y_train[y_train == 0])))\n",
    "print(\"# positive in test set: {}\".format(len(y_test[y_test == 1])),\n",
    "      \"\\n# negative in test set: {}\".format(len(y_test[y_test == 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "# clf = svm.LinearSVC(C=100, loss='hinge', random_state=9, max_iter=500000)\n",
    "# clf = svm.SVC(C=100, kernel='linear', random_state=9)\n",
    "# clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.n_support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 : 0.75 (+/- 0.03) [Naive Bayes]\n",
      "F1 : 0.76 (+/- 0.03) [SVM Linear]\n",
      "F1 : 0.76 (+/- 0.03) [SVM RBF]\n",
      "F1 : 0.76 (+/- 0.03) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "scoring = ['precision_macro', 'recall_macro']\n",
    "estimators = []\n",
    "clf1 = MultinomialNB()\n",
    "estimators.append(clf1)\n",
    "clf2 = svm.SVC(C=100, kernel='linear')\n",
    "estimators.append(clf2)\n",
    "clf3 = svm.SVC(C=100, kernel='rbf', gamma=0.01)\n",
    "estimators.append(clf3)\n",
    "eclf = VotingClassifier(estimators=[('nb', clf1), ('svml', clf2), ('svmr', clf3)], voting='hard')\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Naive Bayes', 'SVM Linear', 'SVM RBF', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='f1')\n",
    "    print(\"F1 : %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = eclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6759, 100)\n"
     ]
    }
   ],
   "source": [
    "if use_all_as_test:\n",
    "    mod_X_test = vstack((test_X, X_test)).todense()\n",
    "    print(mod_X_test.shape)\n",
    "    pred_y = clf.predict(mod_X_test)\n",
    "#     pred_y = clf.predict(X_test)\n",
    "else:\n",
    "    pred_y = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pred_y = clf.predict(X_test)\n",
    "# print(p_pred_y.shape)\n",
    "# if use_all_as_test:\n",
    "#     p_pred_y = np.append(p_pred_y, clf.predict(test_X))\n",
    "# print(p_pred_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "if use_all_as_test:\n",
    "#     mod_y_test = np.append(test_y, y_test)\n",
    "#     print(mod_y_test.shape)\n",
    "    mod_y_test = y_test\n",
    "else:\n",
    "    mod_y_test = y_test\n",
    "tn, fp, fn, tp = confusion_matrix(mod_y_test, p_pred_y).ravel()\n",
    "\n",
    "acc = (tp + tn) / (tn + fp + fn + tp)\n",
    "prec = tp / (tp + fp)\n",
    "rec = tp / (tp + fn)\n",
    "f1 = 2 * prec * rec / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8062645011600929\n",
      "precision 0.7136752136752137\n",
      "recall 0.9100817438692098\n",
      "f1 0.8\n",
      "361 134 33 334\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy\", acc)\n",
    "print(\"precision\", prec)\n",
    "print(\"recall\", rec)\n",
    "print(\"f1\", f1)\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libmesh_fastread_fname = \"/Users/saurabh/workspace/fss/project/data/data-collection/labeled_commits/fastread/abinit_fast_labeled.csv\"\n",
    "# libmesh_df = pd.read_csv(libmesh_fastread_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libmesh_df.columns = [\"hash\", \"abstract\", 'year', \"lnk\", \"label\", \"code\", \"time\"]\n",
    "# codes = libmesh_df.groupby(\"code\")[\"hash\"].count()\n",
    "# print(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_df['hash'] = raw_df['hash'].astype(str)\n",
    "# libmesh_df['hash'] = libmesh_df['hash'].astype(str)\n",
    "# print(libmesh_df.shape)\n",
    "# print(raw_df.shape)\n",
    "# print(libmesh_df.dtypes)\n",
    "# print(raw_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libmesh_df_merged = pd.merge(raw_df, libmesh_df, how='inner', on=['hash'], suffixes=(\"_raw\", \"_libmesh\"))\n",
    "# print(libmesh_df_merged[['hash', 'msg_str', 'buggy_topic', 'buggy', 'code']].head(10))\n",
    "# print(libmesh_df_merged.shape)\n",
    "# libmesh_df_merged_d = libmesh_df_merged[['hash', 'msg_str', 'buggy_topic', 'buggy', 'code']]\n",
    "# print(libmesh_df_merged_d.head(10))\n",
    "# print(libmesh_df_merged_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_libmesh = tf_vectorizer.transform(libmesh_df_merged_d['msg_str'])\n",
    "# X_libmesh = hstack((X_libmesh,np.array(libmesh_df_merged_d['buggy_topic'])[:,None]))\n",
    "# print(X_libmesh.shape)\n",
    "# libmesh_df_merged_d['pred_code'] = clf.predict(X_libmesh)\n",
    "# print(libmesh_df_merged_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_df = libmesh_df_merged_d[['buggy', 'code', 'pred_code']]\n",
    "# print(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_df = y_df[y_df['code'] != 'undetermined']\n",
    "# print(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "# model_knn.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 10\n",
    "# km = KMeans(n_clusters=k, init='k-means++', max_iter=100, n_init=5, verbose=1)\n",
    "# km.fit(X)\n",
    "# %matplotlib inline\n",
    "\n",
    "# plt.hist(km.labels_, bins=k)\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# cluster_assignments_dict = {}\n",
    "# # print(np.where(km.labels_ == i))\n",
    "# # print(raw_df.iloc[79]['msg'])\n",
    "# for i in set(km.labels_):\n",
    "# #     print(i)\n",
    "#     current_cluster_vals = [(raw_df.iloc[x]['msg'], raw_df.iloc[x]['buggy']) for x in np.where(km.labels_ == i)[0]]\n",
    "#     cluster_assignments_dict[i] = current_cluster_vals\n",
    "\n",
    "# cluster_pick = np.random.choice(len(set(km.labels_)))\n",
    "# print('Cluster {0}'.format(cluster_pick))\n",
    "# cluster_assignments_dict[cluster_pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
