{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import string\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from scipy.sparse import hstack, vstack, csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "# projects = ['abinit', 'libmesh', 'lammps', 'mdanalysis']\n",
    "projects = ['lammps']\n",
    "for sp in projects:\n",
    "    s = \"/Users/saurabh/workspace/fss/project/data/data-collection/labeled_commits/{}/\".format(sp)\n",
    "    path = s\n",
    "    files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    all_files.extend(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = \"/Users/saurabh/workspace/fss/project/data/data-collection/labeled_commits/auto/abinit_concat.csv\"\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_df = pd.read_csv(fname, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "raw_df = concatenated_df.drop_duplicates().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buggy\n",
      "0.0    10221\n",
      "1.0      289\n",
      "Name: hash, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "buggies = raw_df.groupby(\"buggy\")[\"hash\"].count()\n",
    "print(buggies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_n = 1000\n",
    "# drop_indices = np.random.choice(raw_df.index, remove_n, replace=False)\n",
    "# new_df = raw_df.drop(drop_indices)\n",
    "# b = new_df.groupby(\"buggy\")[\"hash\"].count()\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index        int64\n",
      "hash        object\n",
      "time        object\n",
      "message     object\n",
      "buggy      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(raw_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10510, 5)\n",
      "(10510, 6)\n"
     ]
    }
   ],
   "source": [
    "# inft = []\n",
    "# for el in y:\n",
    "#     if not np.isfinite(el):\n",
    "#         inft.append(el)\n",
    "# print(el)\n",
    "print(raw_df.shape)\n",
    "raw_df = raw_df.dropna().reset_index()\n",
    "print(raw_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_0      int64\n",
       "index        int64\n",
       "hash        object\n",
       "time        object\n",
       "message     object\n",
       "buggy      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw = raw_df['buggy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = RegexpTokenizer(r'[^\\W_]+|[^\\W_\\s]+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [allow, extended, lagrangian, on, non, scalar,...\n",
      "1                                       [first, draft]\n",
      "2    [draft, the, parallel, construct, based, on, l...\n",
      "3            [got, fix, momentum, kokkos, to, compile]\n",
      "4              [preemptive, change, for, kokkos, cuda]\n",
      "Name: tknz_msg, dtype: object\n"
     ]
    }
   ],
   "source": [
    "raw_df['tknz_msg'] = raw_df['message'].apply(rt.tokenize).apply(lambda tkns: [lemmatizer.lemmatize(w.lower()) for w in tkns])\n",
    "print(raw_df['tknz_msg'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [allow, extended, lagrangian, non, scalar, col...\n",
      "1                                       [first, draft]\n",
      "2          [draft, parallel, construct, based, lambda]\n",
      "3                [got, fix, momentum, kokkos, compile]\n",
      "4                   [preemptive, change, kokkos, cuda]\n",
      "Name: msg, dtype: object\n"
     ]
    }
   ],
   "source": [
    "raw_df['msg'] = raw_df['tknz_msg']\\\n",
    "    .apply(lambda tkns: \\\n",
    "           list(filter(\\\n",
    "                       lambda word: word not in stopset \\\n",
    "                       and word not in string.punctuation\\\n",
    "                       and re.match(r'[^\\W\\d]*$', word) \\\n",
    "                       and len(word) > 2\\\n",
    "                       , tkns)))\n",
    "print(raw_df['msg'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = raw_df['msg'].apply(pd.Series).stack().drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(words))\n",
    "# print(words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['msg_str'] = raw_df['msg'].apply(lambda tkns: ' '.join(tkns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_features = min(1000, len(words))\n",
    "no_features = 100\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=no_features)\n",
    "# tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.95, min_df=2, max_features=no_features)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(raw_df['msg_str'])\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_features=no_features)\n",
    "X_tf = tf_vectorizer.fit_transform(raw_df['msg_str'])\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf vectorized:  (10510, 100)\n",
      "tf vectorized:  (10510, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"tf-idf vectorized: \", X_tfidf.shape)\n",
    "print(\"tf vectorized: \", X_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tf_dense = X_tf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git svn svn svn icms temple edu lammps trunk\n",
      "[('edu', 1), ('git', 1), ('icms', 1), ('lammps', 1), ('svn', 3), ('temple', 1), ('trunk', 1)]\n"
     ]
    }
   ],
   "source": [
    "num = 2786\n",
    "print(raw_df.loc[num]['msg_str'])\n",
    "val = []\n",
    "for idx, d in enumerate(X_tf[num][0].toarray()[0]):\n",
    "#     print(d)\n",
    "    if d > 0:\n",
    "        val.append((tf_feature_names[idx], d))\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 2\n",
    "num_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=no_topics, max_iter=num_iter, learning_method='online', learning_offset=50.,random_state=9, evaluate_every=100).fit(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10510, 2)\n"
     ]
    }
   ],
   "source": [
    "lda_x = lda.transform(X_tfidf)\n",
    "print(lda_x.shape)\n",
    "# print(type(lda_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = [\"bug\", \"fix\", \"wrong\", \"error\", \"fail\", \"problem\", \"patch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_indices = []\n",
    "topic_word_prob = {}\n",
    "feature_names_set = set()\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "#         print(\"Topic %d:\" % (topic_idx))\n",
    "        top_features = []\n",
    "        if topic_idx not in topic_word_prob:\n",
    "            topic_word_prob[topic_idx] = []\n",
    "        top_features = [(feature_names[i], topic[i]) for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_word_prob[topic_idx] = top_features\n",
    "#         print(\" \".join(top_features))\n",
    "        feature_set = set([val[0] for val in top_features])\n",
    "        feature_names_set.update(feature_set)\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([val[0] for val in top_features]))\n",
    "        if any(bug_word in [val[0] for val in top_features] for bug_word in key_words):\n",
    "            topic_indices.append(topic_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "svn lammps git icms trunk temple edu merge request pull\n",
      "Topic 1:\n",
      "fix kokkos user update add pair added file dpd doc\n",
      "[1]\n",
      "{0: [('svn', 2637.3589543962353), ('lammps', 960.2742421224063), ('git', 884.1371609470139), ('icms', 881.325512862348), ('trunk', 879.5968399429112), ('temple', 879.5968396867047), ('edu', 879.5968339604526), ('merge', 521.470964211534), ('request', 462.91064595475694), ('pull', 462.07000328709836)], 1: [('fix', 625.7623708142486), ('kokkos', 375.73730305902194), ('user', 328.5282969051153), ('update', 278.39028798684984), ('add', 257.76324701827133), ('pair', 226.62864165093544), ('added', 217.17801184331202), ('file', 212.16177371815255), ('dpd', 208.17446667019837), ('doc', 195.85601346555936)]}\n",
      "['lammps', 'svn', 'kokkos', 'pair', 'icms', 'add', 'edu', 'dpd', 'temple', 'fix', 'git', 'update', 'request', 'added', 'user', 'file', 'trunk', 'merge', 'pull', 'doc']\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "# display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "display_topics(lda, tf_feature_names, no_top_words)\n",
    "feature_names_list = list(feature_names_set)\n",
    "print(topic_indices)\n",
    "print(topic_word_prob)\n",
    "print(feature_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_top_map_cache = {}\n",
    "def get_topic_top_words(model, feature_names):\n",
    "    if str(model) in model_top_map_cache:\n",
    "        return model_top_map_cache[str(model)]\n",
    "    topic_top_words = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "            top_words = [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "            topic_top_words.append(top_words)\n",
    "    model_top_map_cache[str(model)] = topic_top_words\n",
    "    return topic_top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_topics(words, no_top_words, model, feature_names):\n",
    "    topic_ranks = []\n",
    "    topic_top_words = get_topic_top_words(model, feature_names)\n",
    "    for top_words in topic_top_words:\n",
    "        topic_freq = 0\n",
    "        for w in words:\n",
    "            if w in top_words:\n",
    "                topic_freq += 1\n",
    "        topic_ranks.append(topic_freq)\n",
    "    buggy_topic = 0\n",
    "    max_val = max(topic_ranks)\n",
    "    idx = topic_ranks.index(max_val)\n",
    "    if idx in topic_indices:\n",
    "        buggy_topic = 1\n",
    "    return max_val, idx, buggy_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['topic_freq'], raw_df['topic_id'], raw_df['buggy_topic'] = zip(*raw_df['msg'].apply(lambda tkns: get_top_topics(tkns, 20, lda, tf_feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(raw_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_id  buggy\n",
      "0         0.0      6916\n",
      "          1.0       106\n",
      "1         0.0      3305\n",
      "          1.0       183\n",
      "dtype: int64\n",
      "index:  (1, 0.0) value:  3305\n",
      "index:  (1, 1.0) value:  183\n"
     ]
    }
   ],
   "source": [
    "tops_labels = raw_df.groupby(['topic_id','buggy']).size()\n",
    "print(tops_labels)\n",
    "for i, v in tops_labels.items():\n",
    "    if i[0] in topic_indices:\n",
    "        print('index: ', i, 'value: ', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(lda_x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10510, 14)\n"
     ]
    }
   ],
   "source": [
    "for i in range(no_topics):\n",
    "    topic_name = \"Topic_{}\".format(str(i))\n",
    "    raw_df[topic_name] = pd.Series(lda_x[:, i])\n",
    "print(raw_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_0          int64\n",
       "index            int64\n",
       "hash            object\n",
       "time            object\n",
       "message         object\n",
       "buggy          float64\n",
       "tknz_msg        object\n",
       "msg             object\n",
       "msg_str         object\n",
       "topic_freq       int64\n",
       "topic_id         int64\n",
       "buggy_topic      int64\n",
       "Topic_0        float64\n",
       "Topic_1        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 860,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_word_mapping(words, topic0, topic1, feature_names):\n",
    "    topic_index0 = 0\n",
    "    topic_prob0 = topic0\n",
    "    topic_index1 = 1\n",
    "    topic_prob1 = topic1\n",
    "    topic0_word_prob_map = {}\n",
    "    topic1_word_prob_map = {}\n",
    "    for d in topic_word_prob[topic_index0]:\n",
    "        topic0_word_prob_map[d[0]] = d[1]\n",
    "    for d in topic_word_prob[topic_index1]:\n",
    "        topic1_word_prob_map[d[0]] = d[1]\n",
    "    weighted_words = [0]*(2*no_top_words)\n",
    "    uniq_words = Counter(words)\n",
    "    for w, count in uniq_words.items():\n",
    "        if w not in feature_names_list:\n",
    "            continue\n",
    "        prob = 0\n",
    "        if w in topic0_word_prob_map:\n",
    "            prob += topic_prob0 * count * topic0_word_prob_map[w]\n",
    "        if w in topic1_word_prob_map:\n",
    "            prob += topic_prob1 * count * topic1_word_prob_map[w]\n",
    "        weighted_words[feature_names_list.index(w)] = prob/2\n",
    "    return weighted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['word_prob'] = raw_df.apply(lambda x: doc_word_mapping(x['msg'], x['Topic_0'], x['Topic_1'], tf_feature_names), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[407.7805905668207, 3359.8645411441744, 0, 0, 374.2550016985702, 0, 373.52091796228535, 0, 373.5209203939391, 0, 375.44896844904457, 0, 0, 0, 0, 0, 373.5209205027372, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(raw_df['word_prob'][2786])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "final_df = raw_df[raw_df['buggy'] == 1]\n",
    "if len(topic_indices) > 0:\n",
    "    for idx in topic_indices:\n",
    "        final_df = final_df.append(raw_df[raw_df['topic_id'] == idx])\n",
    "    test_df = raw_df[(raw_df['hash'].apply(lambda x: x not in final_df['hash'].values))]\n",
    "else:\n",
    "    final_df = raw_df\n",
    "# final_df = raw_df\n",
    "use_all_as_test = False\n",
    "if not test_df.empty and test_df.size > 0:\n",
    "    use_all_as_test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = raw_df['buggy']\n",
    "# y_lda = raw_df['topic_id']\n",
    "y_lda = raw_df['buggy_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6754519505233111\n",
      "precision 0.05246559633027523\n",
      "recall 0.6332179930795848\n",
      "f1 0.09690230341540904\n",
      "f2 0.300541960913122\n",
      "6916 3305 106 183\n"
     ]
    }
   ],
   "source": [
    "# print(y_true[:10])\n",
    "# print(y_lda[:10])\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_lda).ravel()\n",
    "\n",
    "acc = (tp + tn) / (tn + fp + fn + tp)\n",
    "prec = tp / (tp + fp)\n",
    "rec = tp / (tp + fn)\n",
    "f1 = 2 * prec * rec / (prec + rec)\n",
    "\n",
    "beta = 3\n",
    "f2 = (1+np.power(beta, 2))*prec*rec/(np.power(beta,2)*prec + rec)\n",
    "\n",
    "print(\"accuracy\", acc)\n",
    "print(\"precision\", prec)\n",
    "print(\"recall\", rec)\n",
    "print(\"f1\", f1)\n",
    "print(\"f2\", f2)\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10510, 15)\n",
      "(3777, 15)\n",
      "(6796, 15)\n"
     ]
    }
   ],
   "source": [
    "print(raw_df.shape)\n",
    "print(final_df.shape)\n",
    "if use_all_as_test:\n",
    "    print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_X_tf = tf_vectorizer.transform(final_df['msg_str'])\n",
    "# X = lda.transform(final_X_tf)\n",
    "# X = tfidf_vectorizer.transform(final_df['msg_str'])\n",
    "X = final_df['word_prob'].values.tolist()\n",
    "y = final_df['buggy']\n",
    "if use_all_as_test:\n",
    "#     test_X_tf = tf_vectorizer.transform(test_df['msg_str'])\n",
    "#     test_X = lda.transform(test_X_tf)\n",
    "#     test_X = tfidf_vectorizer.transform(test_df['msg_str'])\n",
    "    test_X = test_df['word_prob'].values.tolist()\n",
    "    test_y = test_df['buggy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X[1])\n",
    "# print(y.shape)\n",
    "# # X = hstack((X,np.array(final_df['topic_id'])[:,None]))\n",
    "# # X = hstack((X,np.array(final_df['topic_freq'])[:,None]))\n",
    "# # X = hstack((X,np.array(final_df['buggy_topic'])[:,None]))\n",
    "# print(X.shape)\n",
    "# if use_all_as_test:\n",
    "# #     test_X = hstack((test_X,np.array(test_df['topic_id'])[:,None]))\n",
    "# #     test_X = hstack((test_X,np.array(test_df['topic_freq'])[:,None]))\n",
    "# #     test_X = hstack((test_X,np.array(test_df['buggy_topic'])[:,None]))\n",
    "#     print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=9, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# positive in train set: 354 \n",
      "# negative in train set: 2478\n",
      "# positive in test set: 118 \n",
      "# negative in test set: 827\n"
     ]
    }
   ],
   "source": [
    "print(\"# positive in train set: {}\".format(len(y_train[y_train == 1])),\n",
    "      \"\\n# negative in train set: {}\".format(len(y_train[y_train == 0])))\n",
    "print(\"# positive in test set: {}\".format(len(y_test[y_test == 1])),\n",
    "      \"\\n# negative in test set: {}\".format(len(y_test[y_test == 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=50000000, probability=False, random_state=9,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = MultinomialNB()\n",
    "# clf = svm.LinearSVC(C=100, loss='hinge', random_state=9, max_iter=500000)\n",
    "clf = svm.SVC(C=1000, kernel='linear', random_state=9, max_iter=50000000)\n",
    "# clf = DecisionTreeClassifier(random_state=0)\n",
    "# X_train = csr_matrix(X_train)\n",
    "# X_test = csr_matrix(X_test)\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([412, 353], dtype=int32)"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.n_support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring = ['precision_macro', 'recall_macro']\n",
    "# estimators = []\n",
    "# clf1 = MultinomialNB()\n",
    "# estimators.append(clf1)\n",
    "# clf2 = svm.SVC(C=100, kernel='linear')\n",
    "# estimators.append(clf2)\n",
    "# clf3 = svm.SVC(C=100, kernel='rbf', gamma=0.01)\n",
    "# estimators.append(clf3)\n",
    "# eclf = VotingClassifier(estimators=[('nb', clf1), ('svml', clf2), ('svmr', clf3)], voting='hard')\n",
    "# for clf, label in zip([clf1, clf2, clf3, eclf], ['Naive Bayes', 'SVM Linear', 'SVM RBF', 'Ensemble']):\n",
    "#     scores = cross_val_score(clf, X, y, cv=5, scoring='f1')\n",
    "#     print(\"F1 : %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = eclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if use_all_as_test:\n",
    "#     mod_X_test = vstack((test_X, X_test)).todense()\n",
    "#     print(mod_X_test.shape)\n",
    "#     pred_y = clf.predict(mod_X_test)\n",
    "# #     pred_y = clf.predict(X_test)\n",
    "# else:\n",
    "#     pred_y = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(945,)\n",
      "(7741,)\n"
     ]
    }
   ],
   "source": [
    "p_pred_y = clf.predict(X_test)\n",
    "print(p_pred_y.shape)\n",
    "if use_all_as_test:\n",
    "    p_pred_y = np.append(p_pred_y, clf.predict(test_X))\n",
    "print(p_pred_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7741,)\n"
     ]
    }
   ],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "if use_all_as_test:\n",
    "    mod_y_test = np.append(test_y, y_test)\n",
    "    print(mod_y_test.shape)\n",
    "#     mod_y_test = y_test\n",
    "else:\n",
    "    mod_y_test = y_test\n",
    "tn, fp, fn, tp = confusion_matrix(mod_y_test, p_pred_y).ravel()\n",
    "\n",
    "acc = (tp + tn) / (tn + fp + fn + tp)\n",
    "prec = tp / (tp + fp)\n",
    "rec = tp / (tp + fn)\n",
    "f1 = 2 * prec * rec / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8578994961891229\n",
      "precision 0.005040322580645161\n",
      "recall 0.0423728813559322\n",
      "f1 0.009009009009009007\n",
      "6636 987 113 5\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy\", acc)\n",
    "print(\"precision\", prec)\n",
    "print(\"recall\", rec)\n",
    "print(\"f1\", f1)\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libmesh_fastread_fname = \"/Users/saurabh/workspace/fss/project/data/data-collection/labeled_commits/fastread/abinit_fast_labeled.csv\"\n",
    "# libmesh_df = pd.read_csv(libmesh_fastread_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libmesh_df.columns = [\"hash\", \"abstract\", 'year', \"lnk\", \"label\", \"code\", \"time\"]\n",
    "# codes = libmesh_df.groupby(\"code\")[\"hash\"].count()\n",
    "# print(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_df['hash'] = raw_df['hash'].astype(str)\n",
    "# libmesh_df['hash'] = libmesh_df['hash'].astype(str)\n",
    "# print(libmesh_df.shape)\n",
    "# print(raw_df.shape)\n",
    "# print(libmesh_df.dtypes)\n",
    "# print(raw_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libmesh_df_merged = pd.merge(raw_df, libmesh_df, how='inner', on=['hash'], suffixes=(\"_raw\", \"_libmesh\"))\n",
    "# print(libmesh_df_merged[['hash', 'msg_str', 'buggy_topic', 'buggy', 'code']].head(10))\n",
    "# print(libmesh_df_merged.shape)\n",
    "# libmesh_df_merged_d = libmesh_df_merged[['hash', 'msg_str', 'buggy_topic', 'buggy', 'code']]\n",
    "# print(libmesh_df_merged_d.head(10))\n",
    "# print(libmesh_df_merged_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_libmesh = tf_vectorizer.transform(libmesh_df_merged_d['msg_str'])\n",
    "# X_libmesh = hstack((X_libmesh,np.array(libmesh_df_merged_d['buggy_topic'])[:,None]))\n",
    "# print(X_libmesh.shape)\n",
    "# libmesh_df_merged_d['pred_code'] = clf.predict(X_libmesh)\n",
    "# print(libmesh_df_merged_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_df = libmesh_df_merged_d[['buggy', 'code', 'pred_code']]\n",
    "# print(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_df = y_df[y_df['code'] != 'undetermined']\n",
    "# print(y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "# model_knn.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 10\n",
    "# km = KMeans(n_clusters=k, init='k-means++', max_iter=100, n_init=5, verbose=1)\n",
    "# km.fit(X)\n",
    "# %matplotlib inline\n",
    "\n",
    "# plt.hist(km.labels_, bins=k)\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# cluster_assignments_dict = {}\n",
    "# # print(np.where(km.labels_ == i))\n",
    "# # print(raw_df.iloc[79]['msg'])\n",
    "# for i in set(km.labels_):\n",
    "# #     print(i)\n",
    "#     current_cluster_vals = [(raw_df.iloc[x]['msg'], raw_df.iloc[x]['buggy']) for x in np.where(km.labels_ == i)[0]]\n",
    "#     cluster_assignments_dict[i] = current_cluster_vals\n",
    "\n",
    "# cluster_pick = np.random.choice(len(set(km.labels_)))\n",
    "# print('Cluster {0}'.format(cluster_pick))\n",
    "# cluster_assignments_dict[cluster_pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
